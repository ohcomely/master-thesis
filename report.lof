\babel@toc {english}{}\relax 
\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces The bcsstk32 matrix from automotive chassis analysis. This 28,924 Ã— 28,924 symmetric matrix represents an automobile chassis structure analyzed using finite element modeling.}}{1}{figure.caption.1}%
\contentsline {figure}{\numberline {1.2}{\ignorespaces Sparse matrix structure from a quantum transport device. The block-tridiagonal pattern reflects local physical interactions between neighboring spatial layers.}}{2}{figure.caption.2}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Illustration of elimination tree construction for the given sparse symmetric matrix. The sparsity is denoted by filled black circles and the fill-in induced is denoted by hollow red circles.}}{7}{figure.caption.14}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Separator identification process. The separator vertices divide the graph into approximately equal subgraphs}}{11}{figure.caption.16}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Flowchart of the hypergraph-based symmetric DB form algorithm}}{20}{figure.caption.19}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Fill-in ratio (fill-in/original nnz) comparison across different matrix categories}}{29}{figure.caption.22}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Reordering time scaling with matrix size (number of non-zeros) for different algorithms. Each subplot shows the relationship between matrix size and computational time for various reordering methods.}}{31}{figure.caption.23}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Sparsity patterns of matrix 144 with different reordering algorithms applied. The natural ordering (top-left) shows a scattered pattern leading to high fill-in, while optimized reorderings (other panels) demonstrate more defined structures.}}{33}{figure.caption.24}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Similarly, sparsity patterns of matrix copter2 with different reordering algorithms applied.}}{34}{figure.caption.25}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Elimination tree depth comparison across different matrix categories for various reordering algorithms. Lower depth indicates better parallelization potential. Blue indicates lower depth (better), while pink indicates higher depth (worse).}}{35}{figure.caption.26}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Speedup of GPU-accelerated RCM compared to CPU-based RCM on large matrices (over 10K nodes).}}{36}{figure.caption.28}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Reinforcement Learning Framework for Sparse Matrix Reordering using GNNs}}{38}{figure.caption.29}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Recursive calls}}{39}{figure.caption.30}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
